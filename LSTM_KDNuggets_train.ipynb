{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_KDNuggets_train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ba4fQd45ROHm",
        "vjS2BqJGL4ra",
        "PYzR3R-bXPz9",
        "-HW0WBdpaQOl",
        "lutdoxer6t3c"
      ],
      "mount_file_id": "1iKw-D2ViV19wm2IEiabl0B24AyRStdOM",
      "authorship_tag": "ABX9TyMOd4YQlJg2eECsHCqpPJ9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veren4/SMILES_featurization/blob/master/LSTM_KDNuggets_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My--lJljomTg"
      },
      "source": [
        "This notebook ist based on [this tutorial](https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html). The code is from their Github repo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEadlnoYTiRk"
      },
      "source": [
        "Open problems with this model:\n",
        "* Wenn ich in dem Satz, den ich hinten reinfüttere zum Predicten, ein Zeichen habe, das im Trainings-Datensatz nicht vorkam, kriege ich einen Fehler. => Generell muss ich unknown tokens einführen.\n",
        "* Ich schaue das Vokabular des ganzen Datensatzes an. Wenn ich den aber am Anfang nicht einlese, geht das nicht => Vorher bestimmen und hier nur einlesen!\n",
        "* Datensatz einlesen, ohne komplett in den Cache zu laden ([Massive Dataset class](https://github.com/pytorch/text/issues/130))\n",
        "* Adapt lstm size and embedding dim?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba4fQd45ROHm"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGkOXzWZRPMW"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from torch import nn, optim\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "!pip install -q SmilesPE\n",
        "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
        "import pickle\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k65BqjmuO3Vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b8f387-c653-4b63-91ea-e268cab0035c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW79DPFWTA_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697eb1d9-005c-4e64-9369-92ba92bb1f5a"
      },
      "source": [
        "import platform\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Python: ', platform.python_version())\n",
        "print('PyTorch: ', torch.__version__)\n",
        "if(device.type == 'cuda'):\n",
        "  print('Using GPU (cuda)')\n",
        "else:\n",
        "  print('Using CPU!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python:  3.6.9\n",
            "PyTorch:  1.7.0+cu101\n",
            "Using GPU (cuda)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjS2BqJGL4ra"
      },
      "source": [
        "#Metdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYPqmgK0L9Rs"
      },
      "source": [
        "* Number of lines\n",
        "* regex: cut away line number + tabs/spaces\n",
        "* byte offset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXSZkNcSyAFd"
      },
      "source": [
        "wc -l CID-SMILES\\\n",
        "108826964 CID-SMILES\n",
        "\n",
        "108 826 964   lines are in that file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTAl_w-AZudM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0e3c54bf-6846-4add-decf-16af014763f3"
      },
      "source": [
        "'''\n",
        "data_stream = open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/CID-SMILES-first100', 'r')\n",
        "#data_stream = open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/CID-SMILES', 'r')\n",
        "#data_stream = open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/worded_smiles_no_header.csv', 'r')\n",
        "\n",
        "offset_list = list()\n",
        "\n",
        "number_of_lines = 100\n",
        "#number_of_lines = 108826964\n",
        "#number_of_lines = 14\n",
        "\n",
        "for i in range(number_of_lines):\n",
        "  data_stream.readline()\n",
        "  offset_list.append(data_stream.tell())\n",
        "\n",
        "data_stream.close()\n",
        "\n",
        "with open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list_CID-first100.pkl', 'wb') as fid:\n",
        "#with open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list.pkl', 'wb') as fid:\n",
        "#with open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list_worded_smiles_no_header.pkl', 'wb') as fid:\n",
        "\n",
        "  pickle.dump(offset_list, fid)\n",
        "'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ndata_stream = open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/CID-SMILES-first100', 'r')\\n#data_stream = open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/CID-SMILES', 'r')\\n#data_stream = open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/worded_smiles_no_header.csv', 'r')\\n\\noffset_list = list()\\n\\nnumber_of_lines = 100\\n#number_of_lines = 108826964\\n#number_of_lines = 14\\n\\nfor i in range(number_of_lines):\\n  data_stream.readline()\\n  offset_list.append(data_stream.tell())\\n\\ndata_stream.close()\\n\\nwith open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list_CID-first100.pkl', 'wb') as fid:\\n#with open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list.pkl', 'wb') as fid:\\n#with open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list_worded_smiles_no_header.pkl', 'wb') as fid:\\n\\n  pickle.dump(offset_list, fid)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHcfV-T51zrO"
      },
      "source": [
        "with open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list_CID-first100.pkl', 'rb') as fid:\n",
        "     offset_list = pickle.load(fid)\n",
        "\n",
        "#with open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list.pkl', 'rb') as fid:\n",
        "#     offset_list = pickle.load(fid)\n",
        "\n",
        "#with open('/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/offset_list_worded_smiles_no_header.pkl', 'rb') as fid:\n",
        "#     offset_list = pickle.load(fid)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjhbrHK4XLNf"
      },
      "source": [
        "dict_offset = { i : offset_list[i] for i in range(0, len(offset_list) ) }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLfnpyy6sKa"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYzR3R-bXPz9"
      },
      "source": [
        "##Standard Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG-t2-hs6xMF"
      },
      "source": [
        "#import torch\n",
        "#import pandas as pd\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        args,\n",
        "    ):\n",
        "        self.args = args\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = ['UNK', 'SOL', 'EOL', 'PAD', '1', 'N', ')', 'C', 'S', '=', '4', 'O', '(', '2', '3', 'P']\n",
        "\n",
        "        # tokenization dictionaries (numerization)\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "\n",
        "        # numericalize all the tokens\n",
        "        #self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "        # if the token is in word_to index, then the index, otherwise 'UNK' = 0\n",
        "        # [f(x) if condition else g(x) for x in sequence]\n",
        "        #self.words_indexes = [self.word_to_index[w] if (w in uniq_words) else self.word_to_index['UNK'] for w in self.words]\n",
        "        self.words_indexes = [self.word_to_index[w] if (w in self.uniq_words) else 0 for w in self.words]\n",
        "\n",
        "    def load_words(self):\n",
        "\n",
        "        #train_df = pd.read_csv('data/worded_smiles.csv')\n",
        "        infile = '/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/worded_smiles.csv'\n",
        "        with open(infile, \"r\") as file1:\n",
        "            train_df = pd.read_csv(file1)\n",
        "        file1.close()\n",
        "\n",
        "        # Tokenize\n",
        "        train_df['tokenized_SMILES'] = ''\n",
        "        for row in range(train_df.shape[0]):\n",
        "          train_df.loc[row, 'tokenized_SMILES'] = atomwise_tokenizer(train_df.loc[row, 'SMILES'])\n",
        "        \n",
        "        # Padding + SOL + EOL\n",
        "        for row in range(train_df.shape[0]):              # ATTENTION: Are the column indexes correct?!\n",
        "          actual_length = len(train_df.loc[row, 'tokenized_SMILES'])\n",
        "          length_before_delimiters = self.args.sequence_length - 2\n",
        "\n",
        "          if actual_length > length_before_delimiters:\n",
        "            train_df.loc[row, 'tokenized_SMILES'] = train_df.loc[row, 'tokenized_SMILES'][:length_before_delimiters]\n",
        "            train_df.loc[row, 'tokenized_SMILES'].append('EOL')\n",
        "          elif actual_length < length_before_delimiters:\n",
        "            temp = ['UNK']*length_before_delimiters\n",
        "            shortie = train_df.loc[row, 'tokenized_SMILES']\n",
        "            shortie.append('EOL')\n",
        "            temp[:actual_length] = shortie\n",
        "            train_df.loc[row, 'tokenized_SMILES'] = temp\n",
        "          train_df.loc[row, 'tokenized_SMILES'].insert(0, 'SOL')\n",
        "          \n",
        "        # return the whole dataset as 1 list of tokens\n",
        "        total_token_list = []\n",
        "        for row in range(train_df.shape[0]):\n",
        "          total_token_list.extend(train_df.loc[row, 'tokenized_SMILES'])      # can be combined with above.\n",
        "        return total_token_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.args.sequence_length   # !!!!\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.args.sequence_length]),  # input      # turn into cuda tensor?\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.args.sequence_length+1]),    # label\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRlODAX7FHvO"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWb7z_4c_TY-"
      },
      "source": [
        "0 = 'UNK'\\\n",
        "1 = 'SOL'\\\n",
        "2 = 'EOL'\\\n",
        "\n",
        "Es sollte als jeder Batch mit 1 beginnen, und mit 2 enden."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlPbFRlxA46g"
      },
      "source": [
        "dataset = Dataset(args)\n",
        "subset_indices = [0]\n",
        "\n",
        "subset = torch.utils.data.Subset(dataset, subset_indices)\n",
        "\n",
        "#testloader_subset = torch.utils.data.DataLoader(subset, batch_size=args.batch_size, num_workers=0, shuffle=False)\n",
        "testloader_subset = DataLoader(subset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "for batch, (x, y) in enumerate(testloader_subset):\n",
        "            print('\\nbatch: ', batch, '\\n(x, y):', (x, y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mxVQsFyAfBR"
      },
      "source": [
        "#dataset.args.batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnS8RSQhSfe4"
      },
      "source": [
        "#for batch, (x, y) in enumerate(dataloader):\n",
        "#            print('\\nbatch: ', batch, '\\n(x, y):', (x, y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vfwSV1yFJ8S"
      },
      "source": [
        "##Massive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP2DEy_CIoqN"
      },
      "source": [
        "class Massive_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        args,\n",
        "    ):\n",
        "        #self.args = args\n",
        "        self.offsets = dict_offset  #offset_meta\n",
        "        self.length_of_dataset = 14 #dataset_length\n",
        "        self.data_path = '/content/drive/My Drive/Rostlab internship/8_KDNuggets_LSTM_Approach/data/CID-SMILES-first100'\n",
        "        # should be reset in __iter__\n",
        "        self.data_stream = open(self.data_path, 'r')\n",
        "        self.current_offset = 0\n",
        "\n",
        "        self.uniq_words = ['UNK', 'SOL', 'EOL', '(', ')', 'O', 'S', '1', '#', '6', '=', 'C', 'N', '7', '[N+]', '2', '4', 'P', '[O-]', '3', '5', 'Cl']  # vocab for the first 100 of CID_SMILES!\n",
        "        # tokenization dictionaries (numerization)\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_of_dataset\n",
        "\n",
        "    def line_to_instance(self, line):\n",
        "        tokenized_SMILES = atomwise_tokenizer(line)\n",
        "        tokenized_SMILES.insert(0, 'SOL')\n",
        "        tokenized_SMILES.append('EOL')\n",
        "        tokenized_SMILES = [self.word_to_index[w] if (w in self.uniq_words) else self.word_to_index['UNK'] for w in tokenized_SMILES]\n",
        "        return tokenized_SMILES\n",
        "\n",
        "    def __getitem__(self, line):\n",
        "        offset = self.offsets[line]        \n",
        "        self.data_stream.seek(offset)\n",
        "        line = self.data_stream.readline()\n",
        "        line = line.rstrip(\"\\n\")\n",
        "        match = re.match(pattern = \"^\\d+\\\\t(.+)$\", string = line)\n",
        "        if match:\n",
        "          line = match.group(1)\n",
        "        # else    Else: Read next line??     ???????????????????????????????????????????????????\n",
        "        # throw error\n",
        "\n",
        "        instance = self.line_to_instance(line)\n",
        "        label_instance = instance[1:]\n",
        "        label_instance.append(0)    # Determine correct token for last prediction!\n",
        "        \n",
        "        \n",
        "        return (                                                                                   # turn into cuda tensor?\n",
        "            torch.tensor(instance),\n",
        "            torch.tensor(label_instance),  # is the second tensor really used as a label tensor, or is it the other way around?\n",
        "        )\n",
        "        \n",
        "    # Sould I close self.data_stream after training further down?"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HW0WBdpaQOl"
      },
      "source": [
        "##Massive testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPVBzuqKaShq",
        "outputId": "f9094945-34ba-44bd-d6a6-6a02921b9baf"
      },
      "source": [
        "dataset = Massive_Dataset(args)\n",
        "              # offset_length = 100\n",
        "              # offset_meta = dict_offset\n",
        "\n",
        "subset_indices = [0]  # [0,1,2,3,4]\n",
        "\n",
        "subset = torch.utils.data.Subset(dataset, subset_indices)\n",
        "\n",
        "#testloader_subset = torch.utils.data.DataLoader(subset, batch_size=args.batch_size, num_workers=0, shuffle=False)\n",
        "testloader_subset = DataLoader(subset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "for batch, (x, y) in enumerate(testloader_subset):\n",
        "            print('\\nbatch: ', batch,\n",
        "                  '\\n(x, y):', (x, y))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "instance:  [1, 11, 11, 3, 10, 5, 4, 5, 11, 3, 11, 11, 3, 10, 5, 4, 5, 4, 11, 14, 3, 11, 4, 3, 11, 4, 11, 2] \n",
            "\n",
            "\n",
            "batch:  0 \n",
            "(x, y): (tensor([[ 1, 11, 11,  3, 10,  5,  4,  5, 11,  3, 11, 11,  3, 10,  5,  4,  5,  4,\n",
            "         11, 14,  3, 11,  4,  3, 11,  4, 11,  2]]), tensor([[11, 11,  3, 10,  5,  4,  5, 11,  3, 11, 11,  3, 10,  5,  4,  5,  4, 11,\n",
            "         14,  3, 11,  4,  3, 11,  4, 11,  2,  0]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lutdoxer6t3c"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82fmlGvU7EZZ"
      },
      "source": [
        "#import torch\n",
        "#from torch import nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3 #1\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)       # provide predermined number here!\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2#,  #0,\n",
        "            #bidirectional=True\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),    # initializatio with zeros?\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
        "                \n",
        "\n",
        "    #def get_hidden_state(self, x):\n",
        "    #    out, (h_n, c_n) = self.lstm(embed, prev_state)      # problem: usually, I provide the entire dataset as an input here. That is not possible. => I need to extract this information at the end of the training.\n",
        "    #    return h_n, c_n\n",
        "        "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO-qNNhI6vNH"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA38pWgV7IfS"
      },
      "source": [
        "#import argparse\n",
        "#import torch\n",
        "#import numpy as np\n",
        "#from torch import nn, optim\n",
        "#from torch.utils.data import DataLoader\n",
        "\n",
        "def train(dataset, model, args):\n",
        "    model.train()       # set the model to training mode\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=args.batch_size,\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(args.max_epochs):\n",
        "        state_h, state_c = model.init_state(args.sequence_length)   # Here, I need the sequence length for initializing the LSTM anew for this epoch?\n",
        "                                                                    # Why is it always initialized with zeros?        \n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "'''\n",
        "S1/ his is a sequence\n",
        "S2/ a sequence\n",
        "\n",
        "[\n",
        "[-1, 0, 1, 2, 3, -2], [0, 1, 2, 3, -2, -1][/2]\n",
        "[-1, 2, 3, -2, None, None], [2, 3, -2, -1, None, None][/2]\n",
        "]\n",
        "\n",
        "-- in training this is\n",
        "[-1, 0, 1, 2, 3, -2, -1, 2, 3, -2,] [0, 1, 2, 3, -2, -1, 2, 3, -2, -1,]\n",
        "\n",
        "[-1, 0, 1, 2, 3, -2, -1, -1, 2, 3, -2,] [0, 1, 2, 3, -2, -1, -1, 2, 3, -2, -1,]\n",
        "'''\n",
        "# here: slice x and y, leave out the last token (don't predict stuff after)\n",
        "\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "    \n",
        "\n",
        "def predict(dataset, model, text, next_words=100):   # use this function to output the states at all timesteps!\n",
        "    words = text.split(' ')\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "        \n",
        "    return words"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLUaOcnx7HSa"
      },
      "source": [
        "#Apply"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI3Dh4fajbWs"
      },
      "source": [
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--max-epochs', type=int, default=10)\n",
        "parser.add_argument('--batch-size', type=int, default=3)\n",
        "parser.add_argument('--sequence-length', type=int, default=40) # see above: Is this the number of LSTM cells?\n",
        "args = parser.parse_args(\"\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6YP7w00r8Cq"
      },
      "source": [
        "Change the dataset in dataset.py.\\\n",
        "Set max epochs, batch size, seqence length in train.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_g3Ap3WfcX9"
      },
      "source": [
        "#dataset = Dataset(args)\n",
        "dataset = Massive_Dataset(args)\n",
        "\n",
        "model = Model(dataset)   # to cuda"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rsx2f0GmaLD7",
        "outputId": "47aae1c1-393f-4127-8ea4-6af43c5a21ff"
      },
      "source": [
        "train(dataset, model, args)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "instance:  [1, 11, 11, 3, 10, 5, 4, 5, 11, 3, 11, 11, 3, 10, 5, 4, 5, 4, 11, 14, 3, 11, 4, 3, 11, 4, 11, 2] \n",
            "\n",
            "instance:  [1, 11, 7, 10, 11, 11, 3, 11, 3, 11, 3, 10, 11, 7, 4, 11, 3, 10, 5, 4, 5, 4, 5, 4, 5, 2] \n",
            "\n",
            "instance:  [1, 11, 11, 3, 11, 12, 4, 5, 2] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-f1bb79de07bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-e46b77a53307>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, model, args)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Here, I need the sequence length for initializing the LSTM anew for this epoch?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                                     \u001b[0;31m# Why is it always initialized with zeros?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [28] at entry 0 and [26] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_J6Ro_VdEPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ae0b4f-c261-430c-f5d0-5e76ef71e0c6"
      },
      "source": [
        "print(predict(dataset, model, text='C C ( O 2 ) C'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['C', 'C', '(', 'O', '2', ')', 'C', '(', '=', 'O', ')', 'C', 'C', 'N', 'C', '(', '=', 'O', ')', 'C', '(', 'C', '(', 'C', ')', '(', 'C', ')', 'C', 'O', 'P', '(', '=', 'O', ')', '(', 'O', ')', 'O', ')', 'C', 'EOL', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'SOL', 'C', 'C', '(', '=', 'C', 'C', 'C', 'C', '(', '=', 'C', 'C', 'C', 'C', '(', '=', 'C', 'C', 'C', 'C', '(', '=', 'C', 'C', 'C', '1', '=', 'C', '(', 'C', '=', 'C', 'C', '(']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id7H9cuPaf2-"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rqr6_PgmZ0E"
      },
      "source": [
        "!nvidia-smi "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrzBCq20maJY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}