{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "A2CuADTRvLg5",
        "Ien_2TZxaK5h",
        "MWmCtv3dDux6",
        "FnZRAbk7sQNW"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZ7ERfZTi7NVYmk3OpOmke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veren4/SMILES_featurization/blob/master/My_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlF6WsexaFaF"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVNv91KcaKQb"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import pandas as pd\n",
        "#import torchvision    # data loaders for common datasets such as Imagenet, FashionMNIST, MNIST, etc. and data transformers for images\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading external modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGqXmfOEHZJk",
        "outputId": "8784526d-0dcd-49e5-f395-97aacc5d49e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnJ6u21AaSiO",
        "outputId": "ada3605b-01b6-432f-efee-0df2a5d67a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import platform\n",
        "print('Using python: ', platform.python_version())\n",
        "print('Using torch version: ', torch.__version__)\n",
        "print('Using device: ', device)\n",
        "# Machine: 2015 13\" Macbook Pro, i5 dual core\n",
        "\n",
        "#import torch.nn as nn\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using python:  3.6.9\n",
            "Using torch version:  1.6.0+cu101\n",
            "Using device:  cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V_EVk_OBrXc"
      },
      "source": [
        "import tensorboard\n",
        "#print(f\"Tensorboard version: {tensorboard.__version__}\")\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# imports\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsFLyDDJBsxi"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY7Qm_oN8Jk6"
      },
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ_ludYuuK6P"
      },
      "source": [
        "###Set up TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7-rj7zZscKD"
      },
      "source": [
        "[How to TensorBoard](https://pytorch.org/docs/stable/tensorboard.html)\\\n",
        "[PyTorch Tensorboard tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\\\n",
        "([Medium article](https://medium.com/@iamsdt/using-tensorboard-in-google-colab-with-pytorch-458f9bb95212) on TensorBoard in Colab with PyTorch) <- no suitable version available\\\n",
        "[The best tutorial](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/tensorboard_with_pytorch.ipynb#scrollTo=IRSe6eHcFPyT): in a colab notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZtgB9LRS0Gn"
      },
      "source": [
        "[How to run Tensorboard in Colab](https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWyHS1dzSsOs",
        "outputId": "50fe24f8-2bc5-46e5-e4f5-f461f37da3dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2CuADTRvLg5"
      },
      "source": [
        "###Seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxCxMTWYGHoB",
        "outputId": "fa95601a-c0af-435f-e2c5-1164e4289a71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd7e8c34570>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHgd-XA5vPP8"
      },
      "source": [
        "https://discuss.pytorch.org/t/reproducibility-with-all-the-bells-and-whistles/81097"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ien_2TZxaK5h"
      },
      "source": [
        "###Description & documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_WSaelG_wjP"
      },
      "source": [
        "Later: automated batching\\\n",
        "Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKVTR7ZOtoG6"
      },
      "source": [
        "[FloydHub](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)\\\n",
        "[GitHub Minimal example](https://github.com/chrisvdweth/ml-toolkit/blob/master/pytorch/notebooks/minimal-example-lstm-input.ipynb)\\\n",
        "[PyTorch LSTM Beginner guide](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)\\\n",
        "[PyTorch LSTM Guide](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\\\n",
        "[Medium article](https://medium.com/@sunitachoudhary103/generating-molecules-using-a-char-rnn-in-pytorch-16885fd9394b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxGjp7MC4Di6"
      },
      "source": [
        "[deeplearningwizard](https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/): Steps\n",
        "\n",
        "Step 1: Load Dataset\\\n",
        "Step 2: Make Dataset Iterable\\\n",
        "Step 3: Create Model Class\\\n",
        "Step 4: Instantiate Model Class\\\n",
        "Step 5: Instantiate Loss Class\\\n",
        "Step 6: Instantiate Optimizer Class\\\n",
        "Step 7: Train Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie-QsAMTDkvB"
      },
      "source": [
        "##Data preparation (int_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj7Ej_GNW5Oh"
      },
      "source": [
        "infile1 = open('/content/drive/My Drive/Rostlab internship/7_PyTorch/Tokenized_Dataset', 'rb')\n",
        "tokenized_dataset = pickle.load(infile1)\n",
        "infile1.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWmCtv3dDux6"
      },
      "source": [
        "####Vocabulary (all occuring SMILES tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y66-J_eDsNe"
      },
      "source": [
        "alphabet = set()\n",
        "\n",
        "for i in tokenized_dataset:\n",
        "  alphabet.update(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FklgBhnhEQKV"
      },
      "source": [
        "#alphabet    # length: 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnZRAbk7sQNW"
      },
      "source": [
        "####Dictionary (Token alphabet; vocabulary + UNK, EOL etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V7mqxxOz_fO",
        "outputId": "02869fb4-5b5c-4f69-b590-d5e1be37ecca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dict_token_alphabet = {}\n",
        "dict_token_alphabet.update({'UNK': 0, 'SOS': 1, 'EOS':2})\n",
        "\n",
        "index = 3\n",
        "for i in alphabet:\n",
        "  dict_token_alphabet.update({i: index})\n",
        "  index = index+1\n",
        "\n",
        "dict_token_alphabet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(': 3,\n",
              " ')': 4,\n",
              " '1': 11,\n",
              " '2': 9,\n",
              " '3': 5,\n",
              " '4': 7,\n",
              " '=': 6,\n",
              " 'C': 13,\n",
              " 'EOS': 2,\n",
              " 'N': 12,\n",
              " 'O': 10,\n",
              " 'P': 14,\n",
              " 'S': 8,\n",
              " 'SOS': 1,\n",
              " 'UNK': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjroB_Y70xrj"
      },
      "source": [
        "####Vectorize SMILES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlIdYoQL1AAR"
      },
      "source": [
        "int_tokens = [None]*len(tokenized_dataset)    # empty list of length 14\n",
        "\n",
        "for i in range(len(tokenized_dataset)):\n",
        "  int_tokens[i] = [None]*len(tokenized_dataset[i])\n",
        "\n",
        "  for j in range(len(tokenized_dataset[i])):\n",
        "    int_tokens[i][j] = dict_token_alphabet.get(tokenized_dataset[i][j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdV61eVjael7"
      },
      "source": [
        "int_tokens is a list of lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFl5u0YVOZWN",
        "outputId": "346c5a5d-f64f-4e25-b098-1d6bc4741b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.ShortTensor(int_tokens[0])   # or torch.cuda.ShortTensor for a GPU-tensor\n",
        "len(int_tokens[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRDzkqMIbIse",
        "outputId": "f9f5bae9-4d5d-4bd9-9677-bb08567f2728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = torch.ShortTensor(int_tokens[1])\n",
        "len(int_tokens[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1MOGmIcbJ6L",
        "outputId": "f666365c-57b1-4e02-b584-84964c974cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "c = torch.cat(tensors=(a,b), dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-3bd920dbd95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZeNZtL5cAnS",
        "outputId": "9b274816-1857-4701-9510-c54b245b25b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYpWd5WCvWIS",
        "outputId": "91d1a24b-7089-4e6b-e33a-499dfd0acf6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "batch = int_tokens[0]\n",
        "\n",
        "# make a numpy array out of it\n",
        "batch = np.array(batch)\n",
        "\n",
        "# make a PyTorch tensor\n",
        "batch = torch.tensor(batch, dtype=torch.long)\n",
        "\n",
        "print(batch)\n",
        "print('The shape of batch is:', batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7, 11,  7, 11,  7, 11,  7,  4, 13, 11,  9,  4, 10, 11,  4, 10,  4, 10,\n",
            "         4, 10,  4, 10,  7, 11,  9,  4, 10,  7, 11,  9,  4, 10,  4])\n",
            "The shape of batch is: torch.Size([33])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-pIKaFEwQVh"
      },
      "source": [
        "Now we have the first step of having our data in the shape (batch_size, seq_len). to feed it into an LSTM, we still need input_size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OVvhX7WwBIE"
      },
      "source": [
        "####Embedding layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keULFvHEw4RM"
      },
      "source": [
        "Define layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NenQIp9dwFUL"
      },
      "source": [
        "vocab_size = len(dict_token_alphabet)  # 14\n",
        "embed_dim = 10 #<- What does the size of the embeddings mean in my case?\n",
        "\n",
        "word_embedding_layer = nn.Embedding(vocab_size, embed_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIV42R9qw57B"
      },
      "source": [
        "Push batch through layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG5Pd99qwie8",
        "outputId": "3154f28c-1b32-4600-e8bf-56fd7ce88fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch = word_embedding_layer(batch)\n",
        "\n",
        "print('The shape of batch is:', batch.shape)   # 3, 33, 10\n",
        "#print()\n",
        "#print(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of batch is: torch.Size([33, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFSlKKrsxJz8"
      },
      "source": [
        "Now we have want we want: (batch_size, seq_len, input_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dpS7bI6G9Nh"
      },
      "source": [
        "####Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAbKAXUaHYn1"
      },
      "source": [
        "PyTorch Dataloader:\\\n",
        "[PyTorch guide to its Dataloader class](https://pytorch.org/docs/stable/data.html)\\\n",
        "[Parameters](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
        "\n",
        "\\\n",
        "(Alternative to the PyTorch function:  Function from the [Medium article](https://medium.com/@sunitachoudhary103/generating-molecules-using-a-char-rnn-in-pytorch-16885fd9394b))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz0uD-LQ8m0H",
        "outputId": "d34bd8f3-5c93-4ea1-8ad2-e3c09290aa04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 1\n",
        "n_iters = 10\n",
        "num_epochs = n_iters / (len(tokenized_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs, 'epochs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd4fCccsMrYf"
      },
      "source": [
        "Customize my own dataloader.\\\n",
        "What you need is basically pad your variable-length of input and torch.stack() them together into a single tensor. This tensor will then be used as an input to your model.\\\n",
        "[torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mliMI5MyO0gG"
      },
      "source": [
        "#my_stack = nn.utils.rnn.pack_padded_sequence(tokenized_dataset) # ATTENTION: the sequences need to already be padded!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoC197lOMOTP"
      },
      "source": [
        "There is a [pack_padded_sequence](https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence) function that packs a tensor containing padded sequences of variable length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGKhsIruHXhP"
      },
      "source": [
        "my_loader = torch.utils.data.DataLoader(dataset=tokenized_dataset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=True,\n",
        "                                        sampler=None,       # optional: custom Sampler object\n",
        "                                        batch_sampler=None, # optional: provide a custom sampler\n",
        "                                        num_workers=0,      # if positive int => multi-process data loading\n",
        "                                        collate_fn=None,    # optional: custom collate function\n",
        "                                        pin_memory=False,   # to speed it up when working on a GPU\n",
        "                                        drop_last=False,\n",
        "                                        timeout=0,\n",
        "                                        worker_init_fn=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys72nlwTKB29",
        "outputId": "21bef055-b17b-4e3b-ed5e-add7e1fbfb15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "for i in my_loader:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('C',), ('C',), ('(',), ('C',), (')',), ('(',), ('C',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), ('C',), ('C',), ('1',), ('C',), ('(',), ('C',), ('(',), ('C',), ('(',), ('O',), ('1',), (')',), ('N',), ('2',), ('C',), ('=',), ('N',), ('C',), ('3',), ('=',), ('C',), ('(',), ('N',), ('=',), ('C',), ('N',), ('=',), ('C',), ('3',), ('2',), (')',), ('N',), (')',), ('O',), (')',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), (')',), ('C',), ('(',), ('C',), ('(',), ('=',), ('O',), (')',), ('N',), ('C',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('N',), ('C',), ('C',), ('S',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('C',), ('(',), ('C',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('1',), ('=',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('(',), ('=',), ('C',), ('1',), (')',), ('O',), (')',), ('C',), ('=',), ('O',)]\n",
            "[('C',), ('(',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',), (')',), ('S',)]\n",
            "[('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('S',), ('C',), ('C',), ('N',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('C',), ('N',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('(',), ('C',), ('(',), ('C',), (')',), ('(',), ('C',), (')',), ('C',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), ('C',), ('C',), ('1',), ('C',), ('(',), ('C',), ('(',), ('C',), ('(',), ('O',), ('1',), (')',), ('N',), ('2',), ('C',), ('=',), ('N',), ('C',), ('3',), ('=',), ('C',), ('(',), ('N',), ('=',), ('C',), ('N',), ('=',), ('C',), ('3',), ('2',), (')',), ('N',), (')',), ('O',), (')',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('C',)]\n",
            "[('C',), ('(',), ('C',), ('(',), ('C',), ('(',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('(',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('O',), ('C',), ('1',), ('=',), ('C',), ('C',), ('2',), ('=',), ('C',), ('(',), ('C',), ('=',), ('C',), ('N',), ('=',), ('C',), ('2',), ('C',), ('=',), ('C',), ('1',), (')',), ('C',), ('(',), ('C',), ('3',), ('C',), ('C',), ('4',), ('C',), ('C',), ('N',), ('3',), ('C',), ('C',), ('4',), ('(',), ('C',), ('=',), ('C',), (')',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('C',), ('(',), ('C',), (')',), ('(',), ('C',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), ('C',), ('C',), ('1',), ('C',), ('(',), ('C',), ('(',), ('C',), ('(',), ('O',), ('1',), (')',), ('N',), ('2',), ('C',), ('=',), ('N',), ('C',), ('3',), ('=',), ('C',), ('(',), ('N',), ('=',), ('C',), ('N',), ('=',), ('C',), ('3',), ('2',), (')',), ('N',), (')',), ('O',), (')',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), (')',), ('C',), ('(',), ('C',), ('(',), ('=',), ('O',), (')',), ('N',), ('C',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('N',), ('C',), ('C',), ('S',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('C',), ('1',), ('=',), ('C',), ('(',), ('C',), ('=',), ('C',), ('C',), ('(',), ('=',), ('C',), ('1',), (')',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('C',), (')',), ('C',), (')',), ('C',), (')',), ('C',), (')',), ('C',), (')',), ('C',), (')',), ('C',), (')',), ('C',)]\n",
            "[('C',), ('1',), ('=',), ('C',), ('C',), ('(',), ('=',), ('C',), ('C',), ('(',), ('=',), ('C',), ('1',), (')',), ('O',), (')',), ('C',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('(',), ('C',), ('1',), ('C',), ('(',), ('C',), ('(',), ('C',), ('(',), ('C',), ('(',), ('O',), ('1',), (')',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('O',), ('C',), ('2',), ('C',), ('(',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('(',), ('C',), ('(',), ('O',), ('2',), (')',), ('C',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('(',), ('C',), ('(',), ('C',), ('(',), ('C',), ('O',), ('P',), ('(',), ('=',), ('O',), (')',), ('(',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('O',), (')',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('(',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',), (')',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('C',), ('C',), ('(',), ('C',), (')',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',)]\n",
            "[('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('C',), ('C',), ('(',), ('=',), ('O',), (')',), ('O',)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psWMRbCkug_P"
      },
      "source": [
        "I have a map-style dataset, at least for now with this testing dataset. However, when I take the huge PubChem dataset, this might change to iterable-style.\\\n",
        "When automatic batching is enabled, collate_fn is called with a list of data samples at each time. It is expected to collate the input samples into a batch for yielding from the data loader iterator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0WlOGKdgCpH"
      },
      "source": [
        "##Torchtext Dataset Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j-r1bCEjoN8"
      },
      "source": [
        "[How to Torchtext](https://towardsdatascience.com/use-torchtext-to-load-nlp-datasets-part-i-5da6f1c89d84)\\\n",
        "[TorchText Github Documentation](https://github.com/pytorch/text/blob/master/README.rst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr8oJautpYKk"
      },
      "source": [
        "The newline characters need to be removed. Otherwise torchtext cannot read the csv files correctly.\\\n",
        "df_test.comment_text.str.replace(\"\\n\", \" \")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9JLpY2Lrxql",
        "outputId": "cddb1b38-c676-4536-ad92-29f2b9e84e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df_data = pd.read_csv('/content/drive/My Drive/Rostlab internship/7_PyTorch/tokenized_dataset.csv',\n",
        "                      error_bad_lines=False)\n",
        "#df_data[\"comment_text\"] = \\\n",
        "#    df_data.comment_text.str.replace(\"\\n\", \" \")\n",
        "#idx = np.arange(df_data.shape[0])\n",
        "#df_test.to_csv(\"cache/dataset_test.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 3: expected 33 fields, saw 111\\nSkipping line 5: expected 33 fields, saw 45\\nSkipping line 7: expected 33 fields, saw 112\\nSkipping line 10: expected 33 fields, saw 46\\nSkipping line 12: expected 33 fields, saw 105\\nSkipping line 13: expected 33 fields, saw 86\\n'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GYrzkrXH_NQ"
      },
      "source": [
        "import torchtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ENa52QOX4H"
      },
      "source": [
        "[Field class](https://pytorch.org/text/data.html#field) models common text processing datatypes that can be represented by tensors. It holds a **Vocab object** that defines the set of possible values for elements of the field and their corresponding numerical representations. The Field object also holds other parameters relating to how a datatype should be numericalized, such as a **tokenization method** and the kind of Tensor that should be produced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY3SS-RRIGEf"
      },
      "source": [
        "# input: the dataset       output: tensor\n",
        "smiles = torchtext.data.Field(sequential=True,\n",
        "                    use_vocab=True, \n",
        "                    init_token='<sos>', # or should this be numerical?\n",
        "                    eos_token='<eos>',  # same as above\n",
        "                    fix_length=80,    # TODO check for optimal fixed length!\n",
        "                    dtype=torch.int64,    # what is the datatype of a BATCH of examples??\n",
        "                                          # and also again: is this already in the numerical state?\n",
        "                                          # For now, I just leave it at int64 (default)\n",
        "                    preprocessing=None,   # Hier evtl. Padding?\n",
        "                    postprocessing=None,  # oder hier Padding?\n",
        "                    lower=False, \n",
        "                    #tokenize='spacy',         # re.findall(pattern = \"'(\\S+)'\")\n",
        "                    #tokenizer_language='en', \n",
        "                    include_lengths=False, \n",
        "                    batch_first=False, \n",
        "                    pad_token='<pad>', \n",
        "                    unk_token='<unk>', \n",
        "                    pad_first=False, \n",
        "                    truncate_first=False,\n",
        "                    stop_words=None,\n",
        "                    is_target=False)   # Is this a target variable? Kind of yes.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWkDX9uybKWS"
      },
      "source": [
        "my_dataset = torchtext.data.Dataset(\n",
        "    examples='tokenized_dataset_with_header.tsv',  # tsv, weil ich nur 1 Spalte haben möchte.\n",
        "    fields=[('smiles', torchtext.data.Field())]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVoTxGMUgFr8",
        "outputId": "6250b392-81de-4f96-c104-17831bb161dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        }
      },
      "source": [
        "for i in range(100):\n",
        "  print(my_dataset[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t\n",
            "o\n",
            "k\n",
            "e\n",
            "n\n",
            "i\n",
            "z\n",
            "e\n",
            "d\n",
            "_\n",
            "d\n",
            "a\n",
            "t\n",
            "a\n",
            "s\n",
            "e\n",
            "t\n",
            "_\n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            "_\n",
            "h\n",
            "e\n",
            "a\n",
            "d\n",
            "e\n",
            "r\n",
            ".\n",
            "t\n",
            "s\n",
            "v\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-8cd9ee9e070e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWptnErF3eoO"
      },
      "source": [
        "##Putting my data into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI9M5yyA818q",
        "outputId": "4ca61bbc-7346-446c-db88-8200076e19ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 33, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-sb8M0X73Vv"
      },
      "source": [
        "# choose the input parameters\n",
        "input_size = batch.shape[2]\n",
        "hidden_dim = 32\n",
        "\n",
        "# define the model\n",
        "my_LSTM=nn.LSTM(input_size, hidden_dim)\n",
        "\n",
        "# initialise the lstm\n",
        "for parameter in my_LSTM.parameters():\n",
        "    nn.init.normal_(parameter)\n",
        "    #print(parameter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Q_9l4mLh5_",
        "outputId": "97e9a719-2f53-4120-81f5-8121f5928a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "# Model architecture visualization\n",
        "writer = SummaryWriter()    # default `log_dir` is \"runs\"\n",
        "\n",
        "writer.add_graph(model=my_LSTM.cpu(),\n",
        "                 input_to_model=batch,\n",
        "                 verbose=True)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input must have 3 dimensions, got 2\n",
            "Error occurs, No graph saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-60fc95c90503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m writer.add_graph(model=my_LSTM.cpu(),\n\u001b[1;32m      5\u001b[0m                  \u001b[0minput_to_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                  verbose=True)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error occurs, No graph saved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    953\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    954\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                             check_tolerance, strict, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    173\u001b[0m             raise RuntimeError(\n\u001b[1;32m    174\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 175\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2D0RePMqWow",
        "outputId": "07f7e03e-ba09-487e-9b15-a764b9b6449c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "%tensorboard --writer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 2).\n",
              "Contents of stderr:\n",
              "2020-10-21 17:57:25.351254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
              "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
              "                   [--host ADDR] [--bind_all] [--port PORT]\n",
              "                   [--purge_orphaned_data BOOL] [--db URI] [--db_import]\n",
              "                   [--inspect] [--version_tb] [--tag TAG] [--event_file PATH]\n",
              "                   [--path_prefix PATH] [--window_title TEXT]\n",
              "                   [--max_reload_threads COUNT] [--reload_interval SECONDS]\n",
              "                   [--reload_task TYPE] [--reload_multifile BOOL]\n",
              "                   [--reload_multifile_inactive_secs SECONDS]\n",
              "                   [--generic_data TYPE]\n",
              "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
              "                   [--debugger_data_server_grpc_port PORT]\n",
              "                   [--debugger_port PORT]\n",
              "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
              "                   {serve,dev} ...\n",
              "tensorboard: error: unrecognized arguments: --writer"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGzRP_hhTZJW"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrLQwsvCme_q"
      },
      "source": [
        "####Instantiate Loss Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yt9PTizBQXm"
      },
      "source": [
        "#import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv3dM2HM4icS"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK2x4gyg4m40"
      },
      "source": [
        "####Instantiate Optimizer Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erTaZkNZ4wix"
      },
      "source": [
        "# minibatch SGD\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(my_LSTM.parameters(), lr=learning_rate)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI0KzlHp5Vs9",
        "outputId": "6b933b66-e68c-45d7-c850-0435297883d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "#for i in range(len(list(my_LSTM.parameters()))):\n",
        "#    print(list(my_LSTM.parameters())[i].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 10])\n",
            "torch.Size([128, 32])\n",
            "torch.Size([128])\n",
            "torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1FQydbIBBZQ"
      },
      "source": [
        "##Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96ITxePTIQrv",
        "outputId": "310edf81-9ac8-44ee-cd78-bd951f125b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "lstm_out, hidden = my_LSTM(batch)\n",
        "\n",
        "print('The shape of lstm_out is:', lstm_out.shape) # (seq_len, batch_size, hidden_dim)\n",
        "print('The shape of hidden is:', hidden.shape) # (num_layers*num_directions, batch_size, hidden_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-fce9ca7e12a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_LSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The shape of lstm_out is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq_len, batch_size, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The shape of hidden is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (num_layers*num_directions, batch_size, hidden_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    173\u001b[0m             raise RuntimeError(\n\u001b[1;32m    174\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 175\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXEhfDtv0cwm"
      },
      "source": [
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwnWGxp28cWa",
        "outputId": "d363db1b-9e17-4f85-8746-bd303861f0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "runs=10**4\n",
        "\n",
        "print(\"Time Pytorch LSTM {} runs: {:.3f}s\".format(runs, timeit.timeit(\"my_LSTM(batch)\", \n",
        "                                       setup=\"from __main__ import my_LSTM, batch\", \n",
        "                                       number=runs))\n",
        "     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time Pytorch LSTM 10000 runs: 18.690s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65_EsPhh87Hx"
      },
      "source": [
        "[Optuna](https://github.com/optuna/optuna): automated Hyperparameter Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9yRS4Vx9A2U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc8H338EBqZY"
      },
      "source": [
        "##Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb7DvNoKFrsJ"
      },
      "source": [
        "Let's write some stuff to TensorBoard, and log into it to see how things go :)\n",
        "You can log into TensorBoard by running the command from this exercise folder in Terminal:\n",
        "\n",
        "```tensorboard --logdir=runs```\n",
        "\n",
        "For Linux user, you can use open a Terminal and simply run it\n",
        "\n",
        "For Windows user with Anaconda, you may open an Anaconda Prompt and then run the command. Otherwise use your default setup of running python code in cmd.\n",
        "\n",
        "Note that before running the command **you may get into root folder of this Notebook first**. Finally from the command line and then navigating to http://localhost:6006. If everything went well you will be presented with the tensorboard stup and after executing the next cell you should see the following images in TensorBoard.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnX5-BG4FX8z",
        "outputId": "223a072c-bf0f-4918-ed0f-2edfef6cbc49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# write to tensorboard\n",
        "#writer.add_image('four_mnist_images', img_grid)     # I need to write my data here!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-215867d9be08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# write to tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'four_mnist_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_grid\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# I need to write my data here!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'img_grid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFiGnqQWF3XJ",
        "outputId": "2e5a1fe2-70df-4224-b739-a47a9e0b188b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "# Model architecture visualization\n",
        "\n",
        "writer.add_graph(model=word_embedding_layer.cpu(),\n",
        "                 input_to_model=batch,\n",
        "                 verbose=True)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)\n",
            "Error occurs, No graph saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-029555a0e577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m writer.add_graph(model=word_embedding_layer.cpu(),\n\u001b[1;32m      2\u001b[0m                  \u001b[0minput_to_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  verbose=True)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error occurs, No graph saved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_model_mode_for_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    953\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    954\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                             check_tolerance, strict, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdvkUaxIGWul"
      },
      "source": [
        "# Start TensorBoard within the notebook using magics function\n",
        "%tensorboard — logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}